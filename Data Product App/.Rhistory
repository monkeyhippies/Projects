nsv=nearZeroVar(train,saveMetrics=TRUE) ##take out variables with too little variance
train=train[,!nsv$nzv]
##names=sapply(train,class)
##train$cvtd_timestamp=strptime(train$cvtd_timestamp,format="%d/%m/%Y %H:%M")
##PreProcessing: try to select best variables to use
set.seed(25)
variable_scores=vector("list",ncol(train)-1)
names(variable_scores)=names(train[,!names(train) %in% "classe"])
for (name in names(train[,!names(train) %in% "classe"])){
folds=createFolds(y=train$classe,k=5,returnTrain=TRUE)
sums=0
for(i in 1:2){
data=train[,c(name[[1]],"classe")]
obj=train(data$classe~.,data=data,method="rpart")
data2=train[-folds[[1]],]
pred=predict(obj,data2)
accuracy=sum(pred==train[-folds[[1]],"classe"])/nrow(train[-folds[[1]],])
sums=sums+accuracy
}
variable_scores[name[[1]]]=sums/2
}
variable_scores=unlist(variable_scores)
variable_scores=sort(variable_scores,decreasing=TRUE) ##We note there are no variables that particularly stand out to eliminate, although _belt variables seem to be the most important
names=names(train) ##here are the names of columns that we keep; we delete them from our test data too
test=test[,names(test) %in% names]
validation=validation[,names(validation) %in% c(names,"problem_id")]
##Preprocessing: PCA to reduce number of variables further, dividing by each body part, because we assume each body part is correlated
##_arm variables PCA
preProc_arm=preProcess(train[,grep("_arm",colnames(train))],method="pca")
pred_arm=predict(preProc_arm,train[,grep("_arm",colnames(train))])
pred_arm_test=predict(preProc_arm,test[,grep("_arm",colnames(test))])
pred_arm_validation=predict(preProc_arm,validation[,grep("_arm",colnames(validation))])
##_forearm variables PCA
preProc_forearm=preProcess(train[,grep("_forearm",colnames(train))],method="pca")
pred_forearm=predict(preProc_forearm,train[,grep("_forearm",colnames(train))])
pred_forearm_test=predict(preProc_forearm,test[,grep("_forearm",colnames(test))])
pred_forearm_validation=predict(preProc_forearm,validation[,grep("_forearm",colnames(validation))])
##_dumbell variables PCA
preProc_dumbbell=preProcess(train[,grep("_dumbbell",colnames(train))],method="pca")
pred_dumbbell=predict(preProc_dumbbell,train[,grep("_dumbbell",colnames(train))])
pred_dumbbell_test=predict(preProc_dumbbell,test[,grep("_dumbbell",colnames(test))])
pred_dumbbell_validation=predict(preProc_dumbbell,validation[,grep("_dumbbell",colnames(validation))])
##_belt variables PCA
preProc_belt=preProcess(train[,grep("_belt",colnames(train))],method="pca")
pred_belt=predict(preProc_belt,train[,grep("_belt",colnames(train))])
pred_belt_test=predict(preProc_belt,test[,grep("_belt",colnames(test))])
pred_belt_validation=predict(preProc_belt,validation[,grep("_belt",colnames(validation))])
##combine PCAs
trainPCA=data.frame(pred_arm,pred_forearm,pred_dumbbell,pred_belt,train$classe) ##ended up with 32 variables
testPCA=data.frame(pred_arm_test,pred_forearm_test,pred_dumbbell_test,pred_belt_test,test$classe)
validationPCA=data.frame(pred_arm_validation,pred_forearm_validation,pred_dumbbell_validation,pred_belt_validation,validation$problem_id)
names(testPCA)=names(trainPCA)
names(validationPCA)=names(trainPCA)
##LDA, RF, ada, then combine all predictors (majority vote) (normally,I would ksplit the data, run each test on each k split, take average accuracies, to see if I want to use them.  But since it would take forever, I will assume these are the 3 models I want.  Also, I use these because they are the only ones that work in a reasonable amoutn of time)
accuracy1=0
accuracy2=0
accuracy3=0
for (i in 1:5){
index=sample(1:nrow(trainPCA),300)
trainsample=trainPCA[index[1:200],]
testsample=trainPCA(index[201:300],)
obj1=train(train.classe~.,data=trainsample,method="rpart")
obj2=train(train.classe~.,data=trainsample,method="nb")
obj3=train(train.classe~.,data=trainsample,method="lda")
pred1=predict(obj1,testsample)
pred2=predict(obj2,testsample)
pred3=predict(obj3,testsample)
accuracy1=accuracy1+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy2=accuracy2+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy3=accuracy3+sum(pred1==testsample$train.classe)/nrow(testsample)
}
accuracy1=accuracy1/5
accuracy2=accuracy2/5
accuracy3=accuracy3/5 ## We note that test  is best, so we will use it in case of no majority for majority vote of data
##predict on test set
folds=createFolds(y=test$classe,k=5,returnTrain=FALSE)
accuracy1=0
accuracy2=0
accuracy3=0
total_accuracy=0
for (fold in folds){
dataset=testPCA[fold,]
dataset=testPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
accuracy1=accuracy1+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy2=accuracy2+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy3=accuracy3+sum(pred1==dataset$train.classe)/nrow(dataset)
pred12=pred1==pred2
total_pred=ifelse(pred12,as.character(pred1),as.character(pred3))
total_accuracy=total_accuracy+sum(total_pred==as.character(dataset$train.classe))/nrow(dataset)
}
accuracy1=accuracy1/5
accuracy2=accuracy2/5
accuracy3=accuracy3/5
total_accuracy=total_accuracy/5
total_accuracy ##this is predicted accuracy using cross-validation of test set
##test on validation predictions:
dataset=validationPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
pred12=pred1==pred2
total_pred=ifelse(pred12,as.character(pred1),as.character(pred3))
total_pred
##Import data
data=read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
training=data;
validation=read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
inTrain=createDataPartition(y=training$classe,p=.75,list=FALSE)
train=training[inTrain,]
test=training[-inTrain,]
library(caret)
library(klaR)
library(rpart)
set.seed(25)
##exploratory analysis
table(train$classe)
qplot(total_accel_dumbbell,colour=classe,data=train,geom="density")
qplot(total_accel_dumbbell,roll_belt,colour=classe,data=train)
##Preprocess:
sums=sapply(train,function(x){sum(is.na(x))})  ##delete variables with too many NAs
train=train[,sums<10]
train=train[,!colnames(train) %in% "user_name"] ##delete names column
index=grep("_forearm|_arm|_dumbbell|_belt|classe",names(train)) ## only take columns with following words
train=train[,index]
nsv=nearZeroVar(train,saveMetrics=TRUE) ##take out variables with too little variance
train=train[,!nsv$nzv]
##names=sapply(train,class)
##train$cvtd_timestamp=strptime(train$cvtd_timestamp,format="%d/%m/%Y %H:%M")
##PreProcessing: try to select best variables to use
set.seed(25)
variable_scores=vector("list",ncol(train)-1)
names(variable_scores)=names(train[,!names(train) %in% "classe"])
for (name in names(train[,!names(train) %in% "classe"])){
folds=createFolds(y=train$classe,k=5,returnTrain=TRUE)
sums=0
for(i in 1:2){
data=train[,c(name[[1]],"classe")]
obj=train(data$classe~.,data=data,method="rpart")
data2=train[-folds[[1]],]
pred=predict(obj,data2)
accuracy=sum(pred==train[-folds[[1]],"classe"])/nrow(train[-folds[[1]],])
sums=sums+accuracy
}
variable_scores[name[[1]]]=sums/2
}
variable_scores=unlist(variable_scores)
variable_scores=sort(variable_scores,decreasing=TRUE) ##We note there are no variables that particularly stand out to eliminate, although _belt variables seem to be the most important
names=names(train) ##here are the names of columns that we keep; we delete them from our test data too
test=test[,names(test) %in% names]
validation=validation[,names(validation) %in% c(names,"problem_id")]
##Preprocessing: PCA to reduce number of variables further, dividing by each body part, because we assume each body part is correlated
##_arm variables PCA
preProc_arm=preProcess(train[,grep("_arm",colnames(train))],method="pca")
pred_arm=predict(preProc_arm,train[,grep("_arm",colnames(train))])
pred_arm_test=predict(preProc_arm,test[,grep("_arm",colnames(test))])
pred_arm_validation=predict(preProc_arm,validation[,grep("_arm",colnames(validation))])
##_forearm variables PCA
preProc_forearm=preProcess(train[,grep("_forearm",colnames(train))],method="pca")
pred_forearm=predict(preProc_forearm,train[,grep("_forearm",colnames(train))])
pred_forearm_test=predict(preProc_forearm,test[,grep("_forearm",colnames(test))])
pred_forearm_validation=predict(preProc_forearm,validation[,grep("_forearm",colnames(validation))])
##_dumbell variables PCA
preProc_dumbbell=preProcess(train[,grep("_dumbbell",colnames(train))],method="pca")
pred_dumbbell=predict(preProc_dumbbell,train[,grep("_dumbbell",colnames(train))])
pred_dumbbell_test=predict(preProc_dumbbell,test[,grep("_dumbbell",colnames(test))])
pred_dumbbell_validation=predict(preProc_dumbbell,validation[,grep("_dumbbell",colnames(validation))])
##_belt variables PCA
preProc_belt=preProcess(train[,grep("_belt",colnames(train))],method="pca")
pred_belt=predict(preProc_belt,train[,grep("_belt",colnames(train))])
pred_belt_test=predict(preProc_belt,test[,grep("_belt",colnames(test))])
pred_belt_validation=predict(preProc_belt,validation[,grep("_belt",colnames(validation))])
##combine PCAs
trainPCA=data.frame(pred_arm,pred_forearm,pred_dumbbell,pred_belt,train$classe) ##ended up with 32 variables
testPCA=data.frame(pred_arm_test,pred_forearm_test,pred_dumbbell_test,pred_belt_test,test$classe)
validationPCA=data.frame(pred_arm_validation,pred_forearm_validation,pred_dumbbell_validation,pred_belt_validation,validation$problem_id)
names(testPCA)=names(trainPCA)
names(validationPCA)=names(trainPCA)
##LDA, RF, ada, then combine all predictors (majority vote) (normally,I would ksplit the data, run each test on each k split, take average accuracies, to see if I want to use them.  But since it would take forever, I will assume these are the 3 models I want.  Also, I use these because they are the only ones that work in a reasonable amoutn of time)
accuracy1=0
accuracy2=0
accuracy3=0
for (i in 1:5){
index=sample(1:nrow(trainPCA),300)
trainsample=trainPCA[index[1:200],]
testsample=trainPCA(index[201:300],)
obj1=train(train.classe~.,data=trainsample,method="rpart")
obj2=train(train.classe~.,data=trainsample,method="nb")
obj3=train(train.classe~.,data=trainsample,method="lda")
pred1=predict(obj1,testsample)
pred2=predict(obj2,testsample)
pred3=predict(obj3,testsample)
accuracy1=accuracy1+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy2=accuracy2+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy3=accuracy3+sum(pred1==testsample$train.classe)/nrow(testsample)
}
accuracy1=accuracy1/5
accuracy2=accuracy2/5
accuracy3=accuracy3/5 ## We note that test  is best, so we will use it in case of no majority for majority vote of data
##predict on test set
folds=createFolds(y=test$classe,k=5,returnTrain=FALSE)
accuracy1=0
accuracy2=0
accuracy3=0
total_accuracy=0
for (fold in folds){
dataset=testPCA[fold,]
dataset=testPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
accuracy1=accuracy1+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy2=accuracy2+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy3=accuracy3+sum(pred1==dataset$train.classe)/nrow(dataset)
pred12=pred1==pred2
total_pred=ifelse(pred12,as.character(pred1),as.character(pred3))
total_accuracy=total_accuracy+sum(total_pred==as.character(dataset$train.classe))/nrow(dataset)
}
accuracy1=accuracy1/5
accuracy2=accuracy2/5
accuracy3=accuracy3/5
total_accuracy=total_accuracy/5
total_accuracy ##this is predicted accuracy using cross-validation of test set
##test on validation predictions:
dataset=validationPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
pred12=pred1==pred2
total_pred=ifelse(pred12,as.character(pred1),as.character(pred3))
total_pred
for (i in 1:5){
index=sample(1:nrow(trainPCA),300)
trainsample=trainPCA[index[1:200],]
testsample=trainPCA[index[201:300],]
obj1=train(train.classe~.,data=trainsample,method="rpart")
obj2=train(train.classe~.,data=trainsample,method="nb")
obj3=train(train.classe~.,data=trainsample,method="lda")
pred1=predict(obj1,testsample)
pred2=predict(obj2,testsample)
pred3=predict(obj3,testsample)
accuracy1=accuracy1+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy2=accuracy2+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy3=accuracy3+sum(pred1==testsample$train.classe)/nrow(testsample)
}
accuracy1=accuracy1/5
accuracy1
accuracy2=accuracy2/5
accuracy2
accuracy3=accuracy3/5 ## We note that test  is best, so we will use it in case of no majority for majority vote of data
accuracy3
folds=createFolds(y=test$classe,k=5,returnTrain=FALSE)
accuracy1=0
accuracy2=0
accuracy3=0
total_accuracy=0
for (fold in folds){
dataset=testPCA[fold,]
dataset=testPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
accuracy1=accuracy1+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy2=accuracy2+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy3=accuracy3+sum(pred1==dataset$train.classe)/nrow(dataset)
pred12=pred1==pred2
total_pred=ifelse(pred12,as.character(pred1),as.character(pred3))
total_accuracy=total_accuracy+sum(total_pred==as.character(dataset$train.classe))/nrow(dataset)
}
accuracy1=accuracy1/5
accuracy2=accuracy2/5
accuracy3=accuracy3/5
total_accuracy=total_accuracy/5
total_accuracy ##this is predicted accuracy using cross-validation of test set
for (i in 1:5){
index=sample(1:nrow(trainPCA),300)
trainsample=trainPCA[index[1:200],]
testsample=trainPCA[index[201:300],]
obj1=train(train.classe~.,data=trainsample,method="rpart")
obj2=train(train.classe~.,data=trainsample,method="nb")
obj3=train(train.classe~.,data=trainsample,method="lda")
pred1=predict(obj1,testsample)
pred2=predict(obj2,testsample)
pred3=predict(obj3,testsample)
accuracy1=accuracy1+sum(pred1==testsample$train.classe)/nrow(testsample)
accuracy2=accuracy2+sum(pred2==testsample$train.classe)/nrow(testsample)
accuracy3=accuracy3+sum(pred3==testsample$train.classe)/nrow(testsample)
}
accuracy1=accuracy1/5
accuracy1
accuracy2=accuracy2/5
accuracy2
accuracy3=accuracy3/5 ## We note that test  is best, so we will use it in case of no majority for majority vote of data
accuracy3
folds=createFolds(y=test$classe,k=5,returnTrain=FALSE)
accuracy1=0
accuracy2=0
accuracy3=0
total_accuracy=0
for (fold in folds){
dataset=testPCA[fold,]
dataset=testPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
accuracy1=accuracy1+sum(pred1==dataset$train.classe)/nrow(dataset)
accuracy2=accuracy2+sum(pred2==dataset$train.classe)/nrow(dataset)
accuracy3=accuracy3+sum(pred3==dataset$train.classe)/nrow(dataset)
pred13=pred1==pred3
total_pred=ifelse(pred13,as.character(pred1),as.character(pred2))
total_accuracy=total_accuracy+sum(total_pred==as.character(dataset$train.classe))/nrow(dataset)
}
accuracy1=accuracy1/5
accuracy2=accuracy2/5
accuracy3=accuracy3/5
total_accuracy=total_accuracy/5
total_accuracy ##this is predicted accuracy using cross-validation of test set
##test on validation predictions:
dataset=validationPCA
pred1=predict(obj1,dataset)
pred2=predict(obj2,dataset)
pred3=predict(obj3,dataset)
pred12=pred1==pred2
total_pred=ifelse(pred12,as.character(pred1),as.character(pred3))
total_pred
variable_scores
total_accuracy
accuracy3
accuracy2
accuracy1
setInternet2(TRUE)
data=read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
training=data;
validation=read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
library(caret)
library(klaR)
library(rpart)
inTrain=createDataPartition(y=training$classe,p=.75,list=FALSE)
train=training[inTrain,]
test=training[-inTrain,]
set.seed(25)
table(train$classe)
qplot(total_accel_dumbbell,colour=classe,data=train,geom="density")
qplot(total_accel_dumbbell,roll_belt,colour=classe,data=train)
set.seed(25)
variable_scores=vector("list",ncol(train)-1)
names(variable_scores)=names(train[,!names(train) %in% "classe"])
for (name in names(train[,!names(train) %in% "classe"])){
folds=createFolds(y=train$classe,k=5,returnTrain=TRUE)
sums=0
for(i in 1:2){
data=train[,c(name[[1]],"classe")]
obj=train(data$classe~.,data=data,method="rpart")
data2=train[-folds[[1]],]
pred=predict(obj,data2)
accuracy=sum(pred==train[-folds[[1]],"classe"])/nrow(train[-folds[[1]],])
sums=sums+accuracy
}
variable_scores[name[[1]]]=sums/2
}
pandoc +RTS -K64m -RTS -f rst -
?knit
list.files()
knit("Machine Learning Project 2.Rmd")
library(knitr)
knit("Machine Learning Project 2.Rmd")
library(markdown)
markdownToHTML("Machine Learning Project 2.md")
?markdownTOHTML
?markdownToHTML
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html")
+RTS -K64m -RTS
pandoc("Machine Learning Project 2.md",format="html")
library(pandoc)
library(knitr)
pandoc("Machine Learning Project 2.md",format="html")
?markdownToHTML
C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight
do.call(C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight )
command("do.call(C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight"" )
command("C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight")
?command
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html",template="C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html")
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html",template="C:\\Users\\Michael\\Documents\\R\\win-library\\3.1\\rmarkdown\\rmd\\h\\default.html")
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html")
?knit
?knit
knit("Machine Learning Project 2.Rmd","Machine Learning Project3.md",options=options=c('use_xhtml', 'base64_images'))
knit("Machine Learning Project 2.Rmd","Machine Learning Project3.md",options=c('use_xhtml', 'base64_images'))
library(knitr)
library(markdown)
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html",options=c('use_xhtml', 'base64_images'))
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html")
markdownToHTML("Machine Learning Project 2.md","Machine Learning Project 2.html")
mardownHTMLOptions(defaults=TRUE)
markdownHTMLOptions(defaults=TRUE)
?markdownHTMLOptions
?pandoc
pandoc("Machine Learning Project 2.md")
pandoc("Machine Learning Project 2.md")
?pandoc
getwed()
getwd()
system("C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight )
system(""C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight ")
system("C:/Program Files/RStudio/bin/pandoc/pandoc" Preview-c2436e422cb.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output Preview-c2436e422cb.html --smart --email-obfuscation none --self-contained --standalone --section-divs --template "C:\Users\Michael\Documents\R\win-library\3.1\rmarkdown\rmd\h\default.html" --variable "theme:bootstrap" --include-in-header "C:\Users\Michael\AppData\Local\Temp\Rtmpum1IXr\rmarkdown-str15b07d057cd9.html" --mathjax --variable "mathjax-url:https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" --no-highlight --variable highlightjs=Preview-c2436e422cb_files/highlight )
system("C:/Program Files/RStudio/bin/pandoc/pandoc")
install.packages("shiny")
library(manipulate)
library(rCharts)
library(ramnathv-rCharts-2c368c8)
library(rCharts)
install.package(rCharts)
install.packages(rCharts)
install.packages('C:/Users/Michael/Documents/R/win-library/3.1/rCharts')
install.packages('C:\Users\Michael\Downloads\ramnathv-rCharts-2c368c8')
install.packages('C:\\Users\\Michael\\Downloads\\ramnathv-rCharts-2c368c8')
install.packages('C:\\Users\\Michael\\Downloads\\ramnathv-rCharts-2c368c8',repos=NULL)
install.packages('C:\\Users\\Michael\\Downloads\\ramnathv-rCharts-2c368c8.zip',repos=NULL)
dl <- "http://cran.r-project.org/src/contrib/Archive/devtools/devtools_1.1.tar.gz"
fl <- "~/devtools_1.1.tar.gz"
download.file( dl , fl )
install.packages( fl , lib = .libPaths()[1] , repos = NULL , type = "source" )
require( devtools , lib.loc = .libPaths()[1] )
install_github('rCharts', 'ramnathv')
install_github('rCharts', 'ramnathv')
require(devtools)
install_github('rcharts','ramnathv')
deps = c('RCurl', 'RJSONIO', 'whisker', 'yaml')
for (dep in deps){
install.packages(dep)
}
install.packages(dep)
install.packages(dep)
install_github('rcharts','ramnathv')
require(devtools)
install_github('rcharts','ramnathv')
install.packages('https://github.com/ramnathv/rCharts/archive/master.tar.gz',repos=NULL,type='source')
library(rCharts)
devtools::install_github('rstudio/shinyapps')
devtools::install_github('rstudio/shinyapps')
install_github('rstudio/shinyapps')
install_github('rstudio/shinyapps',repos=NULL)
devtools::install_github('rstudio/shinyapps')
library(devtools)
devtools::install_github('rstudio/shinyapps')
install_github( repo = "shinyapps", username="rstudio" )
?install_github
install_github( repo = "shinyapps", username="rstudio" ,auth_user="monkeyhippies",password="de34rfju78ik")
sessionInfo()
?pkgVignettes()
install_github( repo = "shinyapps", username="rstudio" , local=FALSE)
?install_github
?build()
library(knitr)
install_github( repo = "shinyapps", username="rstudio" , local=FALSE)
install_github( repo = "shinyapps", username="rstudio")
install_github( repo = "shinyapps")
install_github( repo = "https://github.com/rstudio/shinyapps")
install_github( repo = "shinyapps", username="rstudio")
pdflatex -v
Sys.which("pdflatex")
Sys.getenv("pdflatex")
Sys.which("pdflatex")
Sys.getenv("pdflatex")
install_github( repo = "shinyapps", username="rstudio")
Sys.getenv("pdflatex")
Sys.which('pdflatex')
getwd()
setwd("./Data Product Apps")
list.files()
setwd("./Data Product App")
library(shiny)
runApp()
runApp()
runApp()
runApp()
hist(1:10)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
output_power=function(n_observations,alpha,delta_mu,sigma){
SE=sigma/sqrt(n_observations)
power=1-pnorm(qnorm(1-alpha)-delta_mu/SE)
return(power)
}
output_power(1000,.05,10,1)
output_power(1000,.05,10,2)
output_power(1000,.04,10,2)
output_power(1000,.04,3,2)
y=2
y
y/2
y/5
seq(-.432,4.32,length.out=100)
seq(-.432,4.32,length.out=100)
seq(-.432121,4.32,length.out=100)
qnorm(1-.05)
qnorm(1-.95)
qnorm(1-.94)
qnorm(1-.93)
qnorm(1-.90)
qnorm(-2)
